{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d52dcc4",
      "metadata": {
        "id": "4d52dcc4"
      },
      "source": [
        "# Ejercicios Ejercicios PySpark clase 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.2.0 pyspark2pmml openscoring==0.5.0\n",
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "!wget https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
        "!wget https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
        "!cp *.jar /usr/local/lib/python3.7/dist-packages/pyspark/jars\n",
        "!wget https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar"
      ],
      "metadata": {
        "id": "QXv1qSRdh7A2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2824946-8e44-4e52-ab12-057b2278cc3f"
      },
      "id": "QXv1qSRdh7A2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.2.0 in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: pyspark2pmml in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: openscoring==0.5.0 in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.2.0) (0.10.9.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openscoring==0.5.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from openscoring==0.5.0) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openscoring==0.5.0) (1.16.0)\n",
            "--2023-09-17 13:50:07--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv.3’\n",
            "\n",
            "iris.csv.3          100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-17 13:50:07 (64.0 MB/s) - ‘iris.csv.3’ saved [3975/3975]\n",
            "\n",
            "--2023-09-17 13:50:07--  https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173873 (170K) [application/java-archive]\n",
            "Saving to: ‘pmml-sparkml-2.2.0.jar.1’\n",
            "\n",
            "pmml-sparkml-2.2.0. 100%[===================>] 169.80K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-09-17 13:50:07 (48.3 MB/s) - ‘pmml-sparkml-2.2.0.jar.1’ saved [173873/173873]\n",
            "\n",
            "--2023-09-17 13:50:07--  https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/58119316/7d46db4f-6687-42a6-bf76-39dd3b4e77ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230917T135007Z&X-Amz-Expires=300&X-Amz-Signature=d33084e6562ae6cfd6e802ec7d9f5321064d6b41269de65b8c32e6ae348d99b4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58119316&response-content-disposition=attachment%3B%20filename%3Dpmml-sparkml-example-executable-2.2.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-17 13:50:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/58119316/7d46db4f-6687-42a6-bf76-39dd3b4e77ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230917T135007Z&X-Amz-Expires=300&X-Amz-Signature=d33084e6562ae6cfd6e802ec7d9f5321064d6b41269de65b8c32e6ae348d99b4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58119316&response-content-disposition=attachment%3B%20filename%3Dpmml-sparkml-example-executable-2.2.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5885135 (5.6M) [application/octet-stream]\n",
            "Saving to: ‘pmml-sparkml-example-executable-2.2.0.jar.1’\n",
            "\n",
            "pmml-sparkml-exampl 100%[===================>]   5.61M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-09-17 13:50:07 (246 MB/s) - ‘pmml-sparkml-example-executable-2.2.0.jar.1’ saved [5885135/5885135]\n",
            "\n",
            "cp: target '/usr/local/lib/python3.7/dist-packages/pyspark/jars' is not a directory\n",
            "--2023-09-17 13:50:07--  https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230917T135007Z&X-Amz-Expires=300&X-Amz-Signature=51d7b9c8e88e3e3d9fb15abb207eb1e514afb3ead09709555a78a06f7e49bacb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-17 13:50:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230917T135007Z&X-Amz-Expires=300&X-Amz-Signature=51d7b9c8e88e3e3d9fb15abb207eb1e514afb3ead09709555a78a06f7e49bacb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25110251 (24M) [application/octet-stream]\n",
            "Saving to: ‘openscoring-server-executable-2.1.0.jar.1’\n",
            "\n",
            "openscoring-server- 100%[===================>]  23.95M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-09-17 13:50:07 (335 MB/s) - ‘openscoring-server-executable-2.1.0.jar.1’ saved [25110251/25110251]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openscoring import Openscoring\n",
        "\n",
        "from pyspark2pmml import PMMLBuilder\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.types import StructType, DoubleType, StringType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import (\n",
        "    MinMaxScaler,\n",
        "    VectorAssembler,\n",
        "    OneHotEncoder,\n",
        "    StringIndexer,\n",
        "    IndexToString\n",
        ")\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "metadata": {
        "id": "uegcpBcnagW_"
      },
      "id": "uegcpBcnagW_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jars = [\n",
        "  'pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  'pmml-sparkml-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-2.2.0.jar'\n",
        "]\n",
        "\n",
        "joined_jars = \",\".join(jars)\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
        "  '--packages org.jpmml:pmml-sparkml:2.0.0 ' + \\\n",
        "  f'--master local[*] --jars {joined_jars} ' + \\\n",
        "  'pyspark-shell'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.jars', joined_jars) \\\n",
        "    .appName(\"PMML\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "Qx3hUPQhYHeL"
      },
      "id": "Qx3hUPQhYHeL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "33fc35f8",
      "metadata": {
        "id": "33fc35f8"
      },
      "source": [
        "## Filtrado y selección de datos en PySpark\n",
        "Dado el siguiente DataFrame de PySpark que contiene información de alumnos junto a sus respectivas notas en varios cursos, aplique los procesos de filtrado y selección de datos para obtener únicamente el nombre, apellido y promedio de notas de aquellos alumnos cuya nota promedio sea igual o mayor a 7.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "data = [('Alicia', 'López', 6, 9, 7),\n",
        "        ('Carlos', 'Rodríguez', 8, 6, 8),\n",
        "        ('Diana', 'Díaz', 9, 10, 9),\n",
        "        ('Fernando', 'Martínez', 4, 3, 5),\n",
        "        ('Gabriela', 'Sánchez', 7, 9, 6)]\n",
        "\n",
        "columns = ['Nombre', 'Apellido', 'Nota Curso 1', 'Nota Curso 2', 'Nota Curso 3']\n",
        "\n",
        "dataFrame = spark.createDataFrame(data, schema=columns)"
      ],
      "metadata": {
        "id": "AtnnVguhN4TU"
      },
      "id": "AtnnVguhN4TU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c39a8c3",
      "metadata": {
        "id": "6c39a8c3"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, round\n",
        "\n",
        "# Calcular promedio de notas\n",
        "\n",
        "# Filtrar alumnos con promedio >= 7\n",
        "\n",
        "# Mostrar resultado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb96cf4",
      "metadata": {
        "id": "8cb96cf4"
      },
      "source": [
        "## Agrupamiento de datos por columna específica\n",
        "Dado el siguiente DataFrame de PySpark que contiene información de ventas de productos por categoría, aplique el proceso de agrupamiento y agregación de datos para obtener el total de ventas por categoría.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data = [('Electrónicos', 30),\n",
        "              ('Hogar', 25),\n",
        "              ('Deportes', 28),\n",
        "              ('Electrónicos', 42),\n",
        "              ('Hogar', 11),\n",
        "              ('Deportes', 15)]\n",
        "\n",
        "sales_columns = ['Categoría', 'Ventas']\n",
        "\n",
        "sales_df = spark.createDataFrame(sales_data, schema=sales_columns)"
      ],
      "metadata": {
        "id": "MswYnNz1OCLR"
      },
      "id": "MswYnNz1OCLR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "334c6de5",
      "metadata": {
        "id": "334c6de5"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "# Agrupar datos por categoría y sumar ventas\n",
        "\n",
        "# Mostrar resultado\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd139a2c",
      "metadata": {
        "id": "cd139a2c"
      },
      "source": [
        "## Conversión de columna categórica a numérica\n",
        "Utilice el siguiente DataFrame de PySpark que contiene información de personas y su género. Convierta la columna 'Género' a numérica, asignando 0 para 'Femenino' y 1 para 'Masculino'."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personas_data = [('Alicia', 'Femenino'),\n",
        "                 ('Carlos', 'Masculino'),\n",
        "                 ('Blanca', 'Femenino'),\n",
        "                 ('Mateo', 'Masculino')]\n",
        "\n",
        "personas_columns = ['Nombre', 'Género']\n",
        "\n",
        "personas_df = spark.createDataFrame(personas_data, schema=personas_columns)"
      ],
      "metadata": {
        "id": "ySBe-3gsOJWy"
      },
      "id": "ySBe-3gsOJWy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b4934a",
      "metadata": {
        "id": "d7b4934a"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Convertir columna 'Género' a numérica\n",
        "\n",
        "# Mostrar resultado\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilizando el conjunto de datos de Iris:\n",
        "\n",
        "*   Cargue el conjunto de datos iris.csv en un DataFrame de PySpark y renombrelos para que tenga una mejor compatibilidad tal como esta en el material\n",
        "\n"
      ],
      "metadata": {
        "id": "aIYdjsyKZdsY"
      },
      "id": "aIYdjsyKZdsY"
    },
    {
      "cell_type": "code",
      "source": [
        "iris_schema = StructType().add('sepal.length', DoubleType()) \\\n",
        "  .add('sepal.width', DoubleType()) \\\n",
        "  .add('petal.length', DoubleType()) \\\n",
        "  .add('petal.width', DoubleType()) \\\n",
        "  .add('variety', StringType())\n",
        "\n",
        "# renaming columns to remove dot for better compatibility\n",
        "iris_df =\n",
        "iris_df.show()"
      ],
      "metadata": {
        "id": "oabW3d2rZxY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8a006b-aeba-4398-d0cf-b862ffe277ad"
      },
      "id": "oabW3d2rZxY1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+------------+-------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.7| Setosa|\n",
            "|        3.4|         4.6|        0.3|         1.4| Setosa|\n",
            "|        3.4|         5.0|        0.2|         1.5| Setosa|\n",
            "|        2.9|         4.4|        0.2|         1.4| Setosa|\n",
            "|        3.1|         4.9|        0.1|         1.5| Setosa|\n",
            "|        3.7|         5.4|        0.2|         1.5| Setosa|\n",
            "|        3.4|         4.8|        0.2|         1.6| Setosa|\n",
            "|        3.0|         4.8|        0.1|         1.4| Setosa|\n",
            "|        3.0|         4.3|        0.1|         1.1| Setosa|\n",
            "|        4.0|         5.8|        0.2|         1.2| Setosa|\n",
            "|        4.4|         5.7|        0.4|         1.5| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.3| Setosa|\n",
            "|        3.5|         5.1|        0.3|         1.4| Setosa|\n",
            "|        3.8|         5.7|        0.3|         1.7| Setosa|\n",
            "|        3.8|         5.1|        0.3|         1.5| Setosa|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilizando PySpark MLlib:   \n",
        "*   Genere una tarea de regresión: Prediga petal_length basándose en las otras características (sepal_length, sepal_width, petal_width)\n",
        "* Divida el conjunto de datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "1.   Entrene y evalue un modelo de regresión lineal para la tarea definida.\n",
        "2.   Exporte este modelo de regresión en formato PMML.\n",
        "\n"
      ],
      "metadata": {
        "id": "VEVOkWpHc6PC"
      },
      "id": "VEVOkWpHc6PC"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZ7lXrkRTLE1"
      },
      "id": "DZ7lXrkRTLE1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}