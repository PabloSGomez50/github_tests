{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d52dcc4",
      "metadata": {
        "id": "4d52dcc4"
      },
      "source": [
        "# Ejercicios Ejercicios PySpark clase 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.2.0 pyspark2pmml openscoring==0.5.0\n",
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "!wget https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
        "!wget https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
        "!cp *.jar /usr/local/lib/python3.7/dist-packages/pyspark/jars\n",
        "!wget https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXv1qSRdh7A2",
        "outputId": "b5ae9320-ca13-443d-88c2-c7a65b4ee21a"
      },
      "id": "QXv1qSRdh7A2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.2.0\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyspark2pmml\n",
            "  Downloading pyspark2pmml-0.5.1.tar.gz (1.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openscoring==0.5.0\n",
            "  Downloading openscoring-0.5.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.2 (from pyspark==3.2.0)\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openscoring==0.5.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from openscoring==0.5.0) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openscoring==0.5.0) (1.16.0)\n",
            "Building wheels for collected packages: pyspark, openscoring, pyspark2pmml\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805893 sha256=1a2047ad82fdfe7bc713af7ea1eb407db56aee8f653a7bf9dbed79cbbe75af49\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/97/d3/8b6d964c8700e4fbb561c71638a92ec55dac9be51eb5fea86d\n",
            "  Building wheel for openscoring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openscoring: filename=openscoring-0.5.0-py3-none-any.whl size=15444 sha256=9ef30276ac807a88129f9632b921933ecf398f90963eb2648b1f22990b3b5ba7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/dc/6d/f693595af7fc650ef112694173f372d1e9dcc692311cd9d6c1\n",
            "  Building wheel for pyspark2pmml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark2pmml: filename=pyspark2pmml-0.5.1-py3-none-any.whl size=2398 sha256=692caea94844dce2eca9bd10f245eb13d5bc6699134ab0856a1c5f27bb55e4ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/45/ab/d2410fea687cbc535f27d7ad887c47051997445f27ca7c4b74\n",
            "Successfully built pyspark openscoring pyspark2pmml\n",
            "Installing collected packages: py4j, pyspark2pmml, pyspark, openscoring\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed openscoring-0.5.0 py4j-0.10.9.2 pyspark-3.2.0 pyspark2pmml-0.5.1\n",
            "--2023-09-18 21:57:40--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv’\n",
            "\n",
            "iris.csv            100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-18 21:57:40 (75.7 MB/s) - ‘iris.csv’ saved [3975/3975]\n",
            "\n",
            "--2023-09-18 21:57:40--  https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173873 (170K) [application/java-archive]\n",
            "Saving to: ‘pmml-sparkml-2.2.0.jar’\n",
            "\n",
            "pmml-sparkml-2.2.0. 100%[===================>] 169.80K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-09-18 21:57:40 (48.3 MB/s) - ‘pmml-sparkml-2.2.0.jar’ saved [173873/173873]\n",
            "\n",
            "--2023-09-18 21:57:40--  https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/58119316/7d46db4f-6687-42a6-bf76-39dd3b4e77ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230918%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230918T215740Z&X-Amz-Expires=300&X-Amz-Signature=c53200af316c1776cabdcd4aee6d8021ea34f3ba5fde1c42cc8861ff39a9ef6e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58119316&response-content-disposition=attachment%3B%20filename%3Dpmml-sparkml-example-executable-2.2.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-18 21:57:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/58119316/7d46db4f-6687-42a6-bf76-39dd3b4e77ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230918%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230918T215740Z&X-Amz-Expires=300&X-Amz-Signature=c53200af316c1776cabdcd4aee6d8021ea34f3ba5fde1c42cc8861ff39a9ef6e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58119316&response-content-disposition=attachment%3B%20filename%3Dpmml-sparkml-example-executable-2.2.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5885135 (5.6M) [application/octet-stream]\n",
            "Saving to: ‘pmml-sparkml-example-executable-2.2.0.jar’\n",
            "\n",
            "pmml-sparkml-exampl 100%[===================>]   5.61M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-09-18 21:57:40 (262 MB/s) - ‘pmml-sparkml-example-executable-2.2.0.jar’ saved [5885135/5885135]\n",
            "\n",
            "cp: target '/usr/local/lib/python3.7/dist-packages/pyspark/jars' is not a directory\n",
            "--2023-09-18 21:57:40--  https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230918%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230918T215740Z&X-Amz-Expires=300&X-Amz-Signature=43623cf8aacb2ed90f1dbbd3cc6df2cd8b42530f4e3ee433382f0002aed07ef9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-18 21:57:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230918%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230918T215740Z&X-Amz-Expires=300&X-Amz-Signature=43623cf8aacb2ed90f1dbbd3cc6df2cd8b42530f4e3ee433382f0002aed07ef9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25110251 (24M) [application/octet-stream]\n",
            "Saving to: ‘openscoring-server-executable-2.1.0.jar’\n",
            "\n",
            "openscoring-server- 100%[===================>]  23.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-09-18 21:57:40 (317 MB/s) - ‘openscoring-server-executable-2.1.0.jar’ saved [25110251/25110251]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openscoring import Openscoring\n",
        "\n",
        "from pyspark2pmml import PMMLBuilder\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.types import StructType, DoubleType, StringType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import (\n",
        "    MinMaxScaler,\n",
        "    VectorAssembler,\n",
        "    OneHotEncoder,\n",
        "    StringIndexer,\n",
        "    IndexToString\n",
        ")\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "metadata": {
        "id": "OOjpezsif5Bc"
      },
      "id": "OOjpezsif5Bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jars = [\n",
        "  'pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  'pmml-sparkml-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-2.2.0.jar'\n",
        "]\n",
        "\n",
        "joined_jars = \",\".join(jars)\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
        "  '--packages org.jpmml:pmml-sparkml:2.0.0 ' + \\\n",
        "  f'--master local[*] --jars {joined_jars} ' + \\\n",
        "  'pyspark-shell'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.jars', joined_jars) \\\n",
        "    .appName(\"PMML\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "n7elpRH6f66s"
      },
      "id": "n7elpRH6f66s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "33fc35f8",
      "metadata": {
        "id": "33fc35f8"
      },
      "source": [
        "## Filtrado y selección de datos en PySpark\n",
        "Dado el siguiente DataFrame de PySpark que contiene información de alumnos junto a sus respectivas notas en varios cursos, aplique los procesos de filtrado y selección de datos para obtener únicamente el nombre, apellido y promedio de notas de aquellos alumnos cuya nota promedio sea igual o mayor a 7.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"PySpark Class 4\").getOrCreate()\n",
        "\n",
        "data = [('Alicia', 'López', 6, 9, 7),\n",
        "        ('Carlos', 'Rodríguez', 8, 6, 8),\n",
        "        ('Diana', 'Díaz', 9, 10, 9),\n",
        "        ('Fernando', 'Martínez', 4, 3, 5),\n",
        "        ('Gabriela', 'Sánchez', 7, 9, 6)]\n",
        "\n",
        "columns = ['Nombre', 'Apellido', 'Nota Curso 1', 'Nota Curso 2', 'Nota Curso 3']\n",
        "\n",
        "dataFrame = spark.createDataFrame(data, schema=columns)"
      ],
      "metadata": {
        "id": "AtnnVguhN4TU"
      },
      "id": "AtnnVguhN4TU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c39a8c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c39a8c3",
        "outputId": "a42cbd06-4d23-452b-80c3-530f63ba2972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+--------+\n",
            "|  Nombre| Apellido|Promedio|\n",
            "+--------+---------+--------+\n",
            "|  Alicia|    López|    7.33|\n",
            "|  Carlos|Rodríguez|    7.33|\n",
            "|   Diana|     Díaz|    9.33|\n",
            "|Gabriela|  Sánchez|    7.33|\n",
            "+--------+---------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, round\n",
        "\n",
        "# Calcular promedio de notas\n",
        "dataFrame = dataFrame.withColumn(\"Promedio\", round((col(\"Nota Curso 1\") + col(\"Nota Curso 2\") + col(\"Nota Curso 3\")) / 3, 2))\n",
        "\n",
        "# Filtrar alumnos con promedio >= 7\n",
        "result = dataFrame.filter(col(\"Promedio\") >= 7).select(\"Nombre\", \"Apellido\", \"Promedio\")\n",
        "\n",
        "# Mostrar resultado\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb96cf4",
      "metadata": {
        "id": "8cb96cf4"
      },
      "source": [
        "## Agrupamiento de datos por columna específica\n",
        "Dado el siguiente DataFrame de PySpark que contiene información de ventas de productos por categoría, aplique el proceso de agrupamiento y agregación de datos para obtener el total de ventas por categoría.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data = [('Electrónicos', 30),\n",
        "              ('Hogar', 25),\n",
        "              ('Deportes', 28),\n",
        "              ('Electrónicos', 42),\n",
        "              ('Hogar', 11),\n",
        "              ('Deportes', 15)]\n",
        "\n",
        "sales_columns = ['Categoría', 'Ventas']\n",
        "\n",
        "sales_df = spark.createDataFrame(sales_data, schema=sales_columns)"
      ],
      "metadata": {
        "id": "MswYnNz1OCLR"
      },
      "id": "MswYnNz1OCLR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "334c6de5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "334c6de5",
        "outputId": "12c2cc5e-6037-456b-cda6-de255aa7a111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+\n",
            "|   Categoría|Total de Ventas|\n",
            "+------------+---------------+\n",
            "|Electrónicos|             72|\n",
            "|    Deportes|             43|\n",
            "|       Hogar|             36|\n",
            "+------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "# Agrupar datos por categoría y sumar ventas\n",
        "result = sales_df.groupBy(\"Categoría\").agg(sum(\"Ventas\").alias(\"Total de Ventas\"))\n",
        "\n",
        "# Mostrar resultado\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd139a2c",
      "metadata": {
        "id": "cd139a2c"
      },
      "source": [
        "## Conversión de columna categórica a numérica\n",
        "Utilice el siguiente DataFrame de PySpark que contiene información de personas y su género. Convierta la columna 'Género' a numérica, asignando 0 para 'Femenino' y 1 para 'Masculino'."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personas_data = [('Alicia', 'Femenino'),\n",
        "                 ('Carlos', 'Masculino'),\n",
        "                 ('Blanca', 'Femenino'),\n",
        "                 ('Mateo', 'Masculino')]\n",
        "\n",
        "personas_columns = ['Nombre', 'Género']\n",
        "\n",
        "personas_df = spark.createDataFrame(personas_data, schema=personas_columns)"
      ],
      "metadata": {
        "id": "ySBe-3gsOJWy"
      },
      "id": "ySBe-3gsOJWy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b4934a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7b4934a",
        "outputId": "56b61eb0-5d0f-40b8-c745-73bb2597c242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---------------+\n",
            "|Nombre|   Género|Género Numérico|\n",
            "+------+---------+---------------+\n",
            "|Alicia| Femenino|              0|\n",
            "|Carlos|Masculino|              1|\n",
            "|Blanca| Femenino|              0|\n",
            "| Mateo|Masculino|              1|\n",
            "+------+---------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Convertir columna 'Género' a numérica\n",
        "result = personas_df.withColumn(\"Género Numérico\", when(col(\"Género\") == \"Femenino\", 0).otherwise(1))\n",
        "\n",
        "# Mostrar resultado\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilizando el conjunto de datos de Iris:\n",
        "\n",
        "*   Cargue el conjunto de datos iris.csv en un DataFrame de PySpark."
      ],
      "metadata": {
        "id": "484311bJgACU"
      },
      "id": "484311bJgACU"
    },
    {
      "cell_type": "code",
      "source": [
        "iris_schema = StructType().add('sepal.length', DoubleType()) \\\n",
        "  .add('sepal.width', DoubleType()) \\\n",
        "  .add('petal.length', DoubleType()) \\\n",
        "  .add('petal.width', DoubleType()) \\\n",
        "  .add('variety', StringType())\n",
        "\n",
        "# renaming columns to remove dot for better compatibility\n",
        "iris_df = spark.read.format('csv') \\\n",
        "  .schema(iris_schema) \\\n",
        "  .option('header', 'true') \\\n",
        "  .load('iris.csv') \\\n",
        "  .select(\n",
        "      col('`sepal.width`').alias('sepal_width'),\n",
        "      col('`sepal.length`').alias('sepal_length'),\n",
        "      col('`petal.width`').alias('petal_width'),\n",
        "      col('`petal.length`').alias('petal_length'),\n",
        "      col('variety')\n",
        "    )\n",
        "# iris_df.show()\n",
        "iris_df.printSchema()"
      ],
      "metadata": {
        "id": "Xo7Ek1vAgBgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d3b7ba-6486-4514-bacc-b8c60fb79283"
      },
      "id": "Xo7Ek1vAgBgi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- variety: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilizando PySpark MLlib:   \n",
        "*   Genere una tarea de regresión: Prediga petal_length basándose en las otras características (sepal_length, sepal_width, petal_width)\n",
        "* Divida el conjunto de datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "1.   Entrene un modelo de regresión lineal para la tarea definida.\n",
        "2.   Exporte este modelo de regresión en formato PMML."
      ],
      "metadata": {
        "id": "XcROV4btgDMs"
      },
      "id": "XcROV4btgDMs"
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = iris_df.randomSplit([0.7, 0.3])\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_width\"],\n",
        "    outputCol=\"features\")\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"petal_length\")\n",
        "pipeline = Pipeline(stages=[assembler, lr])\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Hacer predicciones en los conjuntos de entrenamiento y prueba\n",
        "train_predictions = model.transform(trainingData)\n",
        "test_predictions = model.transform(testData)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de entrenamiento\n",
        "train_evaluator = RegressionEvaluator(labelCol=\"petal_length\", predictionCol=\"prediction\", metricName=\"mse\")\n",
        "train_mse = train_evaluator.evaluate(train_predictions)\n",
        "train_rmse = train_mse**0.5\n",
        "train_accuracy = 1 - train_rmse\n",
        "train_error = train_rmse\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_evaluator = RegressionEvaluator(labelCol=\"petal_length\", predictionCol=\"prediction\", metricName=\"mse\")\n",
        "test_mse = test_evaluator.evaluate(test_predictions)\n",
        "test_rmse = test_mse**0.5\n",
        "test_accuracy = 1 - test_rmse\n",
        "test_error = test_rmse\n",
        "\n",
        "print(f\"Training MSE: {train_mse}, Training RMSE: {train_rmse}, Training Accuracy: {train_accuracy}, Training Error: {train_error}\")\n",
        "print(f\"Test MSE: {test_mse}, Test RMSE: {test_rmse}, Test Accuracy: {test_accuracy}, Test Error: {test_error}\")\n",
        "\n",
        "pmmlBuilder = PMMLBuilder(sc, trainingData, model)\n",
        "pmmlBuilder.buildFile(\"LinearRegressionIris.pmml\")"
      ],
      "metadata": {
        "id": "ipL07wB1gHYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3efb77c3-e34f-4475-f51c-49f8519e2cac"
      },
      "id": "ipL07wB1gHYt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 0.09427025670694064, Training RMSE: 0.3070346180920657, Training Accuracy: 0.6929653819079342, Training Error: 0.3070346180920657\n",
            "Test MSE: 0.11343443252795576, Test RMSE: 0.3368002858192905, Test Accuracy: 0.6631997141807096, Test Error: 0.3368002858192905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/LinearRegressionIris.pmml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}