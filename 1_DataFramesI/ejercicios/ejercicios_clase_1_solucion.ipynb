{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecuta las siguientes celdas para acceder al archivo que usaremos en el ejercicio e instalar spark en esta instancia de colab.\n"
      ],
      "metadata": {
        "id": "feQMdbj2D8v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "with open(\"./energias.csv\", \"wb\") as f:\n",
        "    f.write(requests.get(\"https://raw.githubusercontent.com/engcarlosperezmolero/resources_and_tools/main/data/csv/energias-alternativas.csv\").content)"
      ],
      "metadata": {
        "id": "lEVzciwj60Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark -q"
      ],
      "metadata": {
        "id": "kjeZHjBj7X2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51c463d-02fd-4185-d979-13b95095ecd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio:\n",
        "Crea una variable ```spark``` en donde instancies una SparkSession y una variable ```sc``` en donde inicialices un sparkContext. Luego crea un RDD con el csv generado en las celdas de arriba y consigue el conteo de valores unicos de la columna \"actividad_producto_nombre\" usando transformaciones y acciones.\n",
        "\n",
        "Sugerencias:\n",
        "\n",
        "- el metodo textFile (recuerda que la ruta al archivo es \"./energias.csv\").\n",
        "- la transformacion map (tal vez mas de una vez).\n",
        "- la transformacion groupByKey o reduceByKey (selecciona una y justifica por qu√©).\n",
        "- usa la accion take o la accion collect para conseguir visualizar los resultados (elige una y justifica por qu√©).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Si viste la clase y le mandas un poquito de onda, seguro lo resuelves üòâ. Mucha suerte!!\n",
        "\n",
        "Nota: puede existir mas de una manera de resolver este ejercicio, pero recuerda usar solamente RDD(no Dataframes)"
      ],
      "metadata": {
        "id": "ccD0pgsZBcC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escribe tu codigo aqui"
      ],
      "metadata": {
        "id": "b7HQoohIByDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                                                                                                                                                                                                                                                                                          # Importar las bibliotecas necesarias\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "# Inicializar SparkSession y SparkContext\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local\") \\\n",
        "    .appName(\"Colab\") \\\n",
        "    .config('spark.ui.port', '4050') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Crear un RDD a partir del archivo CSV\n",
        "rdd = sc.textFile(\"./energias.csv\")\n",
        "\n",
        "# Dividir el RDD en comas para su posterior procesamiento\n",
        "rdd_split = rdd.map(lambda x: x.split(\",\"))\n",
        "\n",
        "\n",
        "# Extraer los valores de la columna 'actividad_producto_nombre' del RDD\n",
        "# 'actividad_producto_nombre' es la cuarta columna en el conjunto de datos\n",
        "actividad_producto_nombre_rdd = rdd_split.map(lambda x: x[3])\n",
        "\n",
        "# Transformar el RDD a un formato (clave, 1) para contar valores √∫nicos\n",
        "actividad_producto_nombre_rdd = actividad_producto_nombre_rdd.map(lambda x: (x, 1))\n",
        "\n",
        "# Reducir por clave para obtener el recuento de cada valor √∫nico de 'actividad_producto_nombre'\n",
        "actividad_producto_nombre_count = actividad_producto_nombre_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Tomar los primeros 10 resultados\n",
        "# Usamos 'take' en lugar de 'collect' para evitar traer una gran cantidad de datos al nodo del controlador que puede causar un error de memoria insuficiente\n",
        "top_10_actividad_producto_nombre = actividad_producto_nombre_count.take(10)\n",
        "\n",
        "top_10_actividad_producto_nombre"
      ],
      "metadata": {
        "id": "eW4g7oI2bOWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7abb02-1b17-4a4a-8f18-313feaebb10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actividad_producto_nombre', 1),\n",
              " ('Energia biogas', 552),\n",
              " ('Energia biomasa', 540),\n",
              " ('Energia eolica', 1027),\n",
              " ('Energia nuclear', 456),\n",
              " ('Energia pah', 2172),\n",
              " ('Energia solar', 564)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}