{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1643472e",
      "metadata": {
        "id": "1643472e"
      },
      "source": [
        "##Ejercicios ML con PySpark Vivo Clase 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark -q"
      ],
      "metadata": {
        "id": "8ErZbUiojt4d"
      },
      "id": "8ErZbUiojt4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "72dcf0dc",
      "metadata": {
        "id": "72dcf0dc"
      },
      "source": [
        "## Carga de datos y preparación del dataset\n",
        "Importar el archivo \"titanic.csv\" a un DataFrame de PySpark y seleccionar solo las columnas \"Pclass\", \"Age\" y \"Survived\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888ef2ed",
      "metadata": {
        "id": "888ef2ed"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.types import IntegerType, FloatType\n",
        "\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"Titanic\").getOrCreate()\n",
        "\n",
        "url = \"https://github.com/datasciencedojo/datasets/raw/master/titanic.csv\"\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "titanic_data = spark.read.csv(SparkFiles.get(\"titanic.csv\"), header=True)\n",
        "\n",
        "titanic_data_cleaned ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ef3abb",
      "metadata": {
        "id": "24ef3abb"
      },
      "source": [
        "## Creación de características (features) y etiquetas (labels)\n",
        "Crear un vector de features usando VectorAssembler y renombrar la columna \"Survived\" como \"label\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20962884",
      "metadata": {
        "id": "20962884"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c1a30b",
      "metadata": {
        "id": "d9c1a30b"
      },
      "source": [
        "## Entrenamiento del modelo de clasificación y evaluación de su rendimiento\n",
        "Entrenar un modelo de Regresión Logística usando el dataset de entrenamiento y evaluar su desempeño utilizando la métrica \"Accuracy\" en el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955110da",
      "metadata": {
        "id": "955110da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8df0820-8726-47e7-b0b7-cebb33c698ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.743006993006993\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "print(\"Test Accuracy: \", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}