{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalamos PySpark"
      ],
      "metadata": {
        "id": "1GVUwUj7MaQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7pP2ZpMMVVe",
        "outputId": "da9406a7-edd5-4bbd-a808-c0a9437763c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraemos los datos:"
      ],
      "metadata": {
        "id": "XWZcuzgLMeGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la sesion de Spark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "_XVOJPpuMwDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!wget https://storage.googleapis.com/humai-datasets/datasets/Tweets.csv"
      ],
      "metadata": {
        "id": "zPKKBZhz8I5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Tweets.csv')[['airline_sentiment', 'text']]\n",
        "raw_df = spark.createDataFrame(df)\n",
        "raw_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-yHpkVbNVn2",
        "outputId": "2c0436e8-3523-4ad3-d52a-1a374000ce48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------------------+\n",
            "|airline_sentiment|                text|\n",
            "+-----------------+--------------------+\n",
            "|          neutral|@VirginAmerica Wh...|\n",
            "|         positive|@VirginAmerica pl...|\n",
            "|          neutral|@VirginAmerica I ...|\n",
            "|         negative|@VirginAmerica it...|\n",
            "|         negative|@VirginAmerica an...|\n",
            "|         negative|@VirginAmerica se...|\n",
            "|         positive|@VirginAmerica ye...|\n",
            "|          neutral|@VirginAmerica Re...|\n",
            "|         positive|@virginamerica We...|\n",
            "|         positive|@VirginAmerica it...|\n",
            "|          neutral|@VirginAmerica di...|\n",
            "|         positive|@VirginAmerica I ...|\n",
            "|         positive|@VirginAmerica Th...|\n",
            "|         positive|@VirginAmerica @v...|\n",
            "|         positive|@VirginAmerica Th...|\n",
            "|         negative|@VirginAmerica SF...|\n",
            "|         positive|@VirginAmerica So...|\n",
            "|         negative|@VirginAmerica  I...|\n",
            "|         positive|I ❤️ flying @Virg...|\n",
            "|         positive|@VirginAmerica yo...|\n",
            "+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"words_filtered\", outputCol=\"rawFeatures\", numFeatures=20)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "\n",
        "# Convertimos las feature textuales en indices.\n",
        "label_indexer = StringIndexer(inputCol='airline_sentiment', outputCol='airline_sentiment_label') #.fit(transformed_data)\n",
        "\n",
        "# Creamos las mismas transformacion de los pasos anteriores de antemano.\n",
        "dt = DecisionTreeClassifier(labelCol=\"airline_sentiment_label\", featuresCol=\"features\")\n",
        "\n",
        "# Creamos el Pipeline que encadena las transformaciones.\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, label_indexer, dt])\n",
        "\n",
        "\n",
        "(train_data, test_data) = raw_df.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Fitteamos todos los pasos del pipeline.\n",
        "model = pipeline.fit(train_data)\n"
      ],
      "metadata": {
        "id": "2q-IDI4-PUIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = dict(list(enumerate(model.stages[4].labels)))\n",
        "print(f\"Labels de cada sentiment: {label_map}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aUqQ-MZc4PW",
        "outputId": "f393a917-4fe9-4e23-b9ff-54a946cb87f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels de cada sentiment: {0: 'negative', 1: 'neutral', 2: 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)"
      ],
      "metadata": {
        "id": "_5AzuJBAXll1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"airline_sentiment_label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"precisionByLabel\"\n",
        ")\n",
        "\n",
        "for label_index, label_name in label_map.items():\n",
        "    score = evaluator.evaluate(\n",
        "        predictions, {\n",
        "            evaluator.metricName: \"precisionByLabel\",\n",
        "            evaluator.metricLabel: float(label_index),\n",
        "        }\n",
        "    )\n",
        "    print(f\"Score para la clase {label_name} = {round(score, 3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnZ52ekIUVaB",
        "outputId": "95a603e4-6cca-4cdc-9ba8-9e3da5f67ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score para la clase negative = 0.629\n",
            "Score para la clase neutral = 0.0\n",
            "Score para la clase positive = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Labels reales (ground truth)\")\n",
        "print(predictions.toPandas()['airline_sentiment_label'].value_counts())\n",
        "print(\"\")\n",
        "\n",
        "print(\"Labels predichas\")\n",
        "print(predictions.toPandas()['prediction'].value_counts())\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM2st6wtasz3",
        "outputId": "6d17fd47-24d8-4854-ef19-dc566b530827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels reales (ground truth)\n",
            "0.0    2750\n",
            "1.0     943\n",
            "2.0     682\n",
            "Name: airline_sentiment_label, dtype: int64\n",
            "\n",
            "Labels predichas\n",
            "0.0    4375\n",
            "Name: prediction, dtype: int64\n",
            "\n"
          ]
        }
      ]
    }
  ]
}