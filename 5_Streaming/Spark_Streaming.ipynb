{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK3_fvXVgjB5"
      },
      "source": [
        "# Spark Streaming\n",
        "\n",
        "Apache Spark es un sistema de procesamiento de datos escalable y tolearnte a fallas que soporta tanto operaciones nativas batch y streaming. **Spark Streaming** es una extensión de la API core de Spark que permite a los ingenieros de datos y data scientists procesar data en real time de varias fuentes como (pero no limitada a) Kafka, Flume y Kinesis. La data procesada puede ser enviada a otros file systems, bases de datos, dashboards, etc.\n",
        "\n",
        "## DStream o Discretized Stream (Stream Discretizado)\n",
        "\n",
        "Su abstracción clave es llamada Discretized Stream o más conocido como **DStream**, la cual representa el stream de la data dividida en mini batches. Los DStreams estan construidos sobre los RDDs (resilient distributed dataset), que es la abstracción core de Spark. Estos RDDs son una colección de elementos particionados entre nodos del cluster que pueden ser operados en paralelo. Los RDDs son creados tanto desde un file de Hadoop o cualquier colección creada y transformada por el driver. Los usuarios pueden pedir a Spark que persista los RDDs en memoria para que puedan ser reutilizados de manera eficiente entre operaciones paralelas. Finalmente, los RDDs pueden recuperarse automaticamente de fallas. Esta caracteristica de poder recalcularse se le llama **idempotencia**.\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/humai-datasets/imagenes/big_data_pyspark/5_Streaming/streaming-dstream.png\" alt=\"DStream Image\" />\n",
        "\n",
        "</center>\n",
        "\n",
        "## Streaming Context\n",
        "\n",
        "Además de la forma que veremos en este colab, existe otra manera de inicializar aplicaciones de Spark Streaming. De la misma manera que otras aplicaciones utilizan el conocido:\n",
        "\n",
        "```python\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "```\n",
        "\n",
        "Las aplicaciones de streaming utilizan un objeto llamado `StreamingContext`. Al código anterior se le agrega este objeto y queda de la siguiente manera:\n",
        "\n",
        "```python\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "ssc = StreamingContext(sc, 1)\n",
        "```\n",
        "\n",
        "Como ven el `StreamingContext` recibe dos argumentos. El primero es el `SparkContext` de la aplicación. El segundo es el numero de segundos con el que Spark va a batchear la data entrante. En este caso, la data va a entrar y cada un segundo va a ejecutar el procesamiento de la aplicación.\n",
        "\n",
        "El beneficio de tener un objeto como `StreamingContext` es que se pueden utilizar `Receivers`, otro objeto que recibe data asincrónica de Spark, o implementar los propios. En mi caso, yo necesitaba consumir imágenes de cámaras de seguridad entonces implemente un `RTSPReceiver` donde `rtsp` es un protocolo de video.\n",
        "\n",
        "Los `Receivers` que existen son: `socketTextStream` el cual abre un socket y espera data a través de TCP, `fileStream` el cual mira un file system y espera nuevos archivos, entre otros.\n",
        "\n",
        "## Integración\n",
        "\n",
        "Gracias a que Spark Streaming esta montado sobre los RDDs, permite que la integración con otros componentes de Spark como Spark SQL o MLlib sea consistente y logica.\n",
        "\n",
        "El hecho de que Spark tenga solo un motor de ejecución y un modelo de programación para streaming y batch lleva a algunos beneficios únicos sobre otros modelos de programación streaming:\n",
        "\n",
        "- Rápida recuperación de fallas\n",
        "- Mejor balanceo de la carga y uso de recursos\n",
        "- Combinación de data streaming y estática\n",
        "- Integración nativa con librerías de procesamiento avanzadas (SQL, Machine Learning, procesamiento de grafos)\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/humai-datasets/imagenes/big_data_pyspark/5_Streaming/Apache-Spark-Streaming-ecosystem-diagram.png\" alt=\"Spark Streaming Integration\" />\n",
        "\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynyDZlkUg5Sv"
      },
      "source": [
        "## Dependencias\n",
        "\n",
        "Aquí se instalan las dependencias y descargan los archivos necesarios para correr este colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT0h2lxAgiev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063465cd-3b09-4cf7-ceba-d30150d2f27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.2.0 in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.2.0) (0.10.9.2)\n",
            "--2023-10-02 21:25:31--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv.1’\n",
            "\n",
            "iris.csv.1          100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-02 21:25:31 (69.9 MB/s) - ‘iris.csv.1’ saved [3975/3975]\n",
            "\n",
            "--2023-10-02 21:25:31--  https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231002%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231002T212531Z&X-Amz-Expires=300&X-Amz-Signature=17419c4f45dc96d7e25344061053906b45e7bf7f1410461ab31b8e55f17556b5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-02 21:25:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231002%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231002T212531Z&X-Amz-Expires=300&X-Amz-Signature=17419c4f45dc96d7e25344061053906b45e7bf7f1410461ab31b8e55f17556b5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25110251 (24M) [application/octet-stream]\n",
            "Saving to: ‘openscoring-server-executable-2.1.0.jar.1’\n",
            "\n",
            "openscoring-server- 100%[===================>]  23.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-02 21:25:31 (161 MB/s) - ‘openscoring-server-executable-2.1.0.jar.1’ saved [25110251/25110251]\n",
            "\n",
            "--2023-10-02 21:25:31--  https://downloads.apache.org/kafka/3.4.1/kafka_2.12-3.4.1.tgz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 106809260 (102M) [application/x-gzip]\n",
            "Saving to: ‘kafka_2.12-3.4.1.tgz.1’\n",
            "\n",
            "kafka_2.12-3.4.1.tg 100%[===================>] 101.86M  31.1MB/s    in 3.5s    \n",
            "\n",
            "2023-10-02 21:25:35 (29.4 MB/s) - ‘kafka_2.12-3.4.1.tgz.1’ saved [106809260/106809260]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.2.0\n",
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "!wget https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar\n",
        "!wget https://downloads.apache.org/kafka/3.4.1/kafka_2.12-3.4.1.tgz\n",
        "!tar -xzf kafka_2.12-3.4.1.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kafka\n",
        "\n",
        "Apache Kafka es un sistema de streaming de eventos distribuido de código abierto utilizado por miles de compañías para data pipielines de alta performance, streaming analytics, integración de datos y aplicaciones *mission critical*.\n",
        "\n",
        "## Arquitectura de Kafka\n",
        "\n",
        "### Mensajes\n",
        "\n",
        "Como mencionamos, Kafka envia mensajes a alta velocidad. Para performance óptima, estos mensajes deben ser pequeños: solo algunas columnas. Los mensajes pueden estar serializados de múltiples maneras como AVRO, Proto, String, Bytes, etc. En este caso vamos a pasar un JSON a string y usar el `StringSerializer`. Luego, en la lectura, vamos a desarmar el json en columnas nuevamente. Los mensajes tienen una clave y un valor. La clave va a indicar a qué *broker*, o máquina dentro del cluster, el mensaje caera; y el valor es el valor del mensaje en sí.\n",
        "\n",
        "### Topics\n",
        "\n",
        "Los mensajes caen en *topics* o tópicos. Es la manera para que los usuarios (producers y consumers) sepan a donde tienen que escribir mensajes y de donde tienen que leerlos. Los tópicos tienen un nombre y configuración asociada que veremos a continuación.\n",
        "\n",
        "### Producers\n",
        "\n",
        "Los *producers* son los usuarios, aplicaciones o entidades que escriben data al topico. Estos se conectan con los *brokers*, definen el tópico al cuál escribir, arman el mensaje con clave y valor, lo serializan y envian.\n",
        "\n",
        "### Consumers\n",
        "\n",
        "Del otro lado de los producers, estan los *consumers*, los cuales escuchan mensajes asincrónicamente y ejecutan acciones con esos mensajes. Estas acciones pueden ser transformaciones, nuevos eventos, acciones dentro de un sistema de eventos, etc. De la misma manera que los producers, los consumers deben definir los brokers, topico y métodos de serialización. Cuando un consumer lee un mensaje del cluster, tiene la opción de hacer un *commit*. Esto le indica al cluster que el mensaje fue leido, de manera que si una operación falla y el commit no se hace, puede hacerse nuevamente más tarde por otro consumer.\n",
        "\n",
        "### Consumer groups\n",
        "\n",
        "Los *consumer groups* es la manera que tiene kafka de paralelizar los mensajes. Todos los consumers dentro de un consumer group tienen el mismo id. En vez de tener solo un consumer consumiendo todos los mensajes, puedo tener muchos en paralelo, pero ¿Cómo hago para que no lleguen los mismos mensajes a diferentes consumers? Esta abstracción se encarga de esto. Automáticamente, se distribuyen los mensajes de manera equitativa entre los consumers dentro del grupo para paralelizar de la mejor manera posible. La cantidad de consumer groups es configurable, por lo que la escalabilidad (lineal) también lo es.\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://sp-ao.shortpixel.ai/client/to_auto,q_lossy,ret_img,w_2231,h_1541/https://www.instaclustr.com/wp-content/uploads/2018/08/Kongo-Blog-6.3-graph_1.6B-1.png\" alt=\"Kafka Scalability Graph\" />\n",
        "\n",
        "</center>\n",
        "\n",
        "### Brokers\n",
        "\n",
        "Un cluster de Kafka esta compuesto de uno o más servers llamados *brokers*. En el contexto de Kafka, un broker es un servidor que puede mantener múltiples tópicos y particiones. Se los identifica con un ID único. Una conexión con cualquier nodo broker implica una conexión con el cluster completo. Si hay más de un broker en el cluster estos no *deben* mantener toda la información de un tópico (a pesar de que si puedan dependiendo del factor de replicación definido).\n",
        "\n",
        "### Particiones\n",
        "\n",
        "Los tópicos de Kafka estan divididos en un número configurable de partes llamadas *particiones*. Estas permiten que múltiples consumers puedan leer la data de un topico en particular de forma paralela. Las particiones se separan en orden y el número de particiones se especifica cuando se crea el tópico (puede ser cambiado). Cada broker maneja la data para su partición en particular. Como mencionamos, la clave del mensaje determina en qué partición cae el mensaje. Si la clave no esta definida, se decide de manera round-robin. Tener en cuenta que en la mayoría de los casos va a ser más eficiente pensar una lógica para la clave.\n",
        "\n",
        "### Réplicas\n",
        "\n",
        "Las *réplicas* son como backups de las particiones de Kafka. Sirven para asegurar que no haya pérdida de datos en caso de falla o apagado planeado. Las particiones de un tópico son guardadas en más de un broker. Estas copias son las réplicas. Tener en cuenta que a mayor cantidad de replicas, mayor disponibilidad pero mayor latencia. Si se pueden perder mensajes, es mejor no tener replicación. Si es importante que no se pierdan mensajes, mejor tener una replicación que sirva para el caso de negocio.\n",
        "\n",
        "### Misceláneo\n",
        "\n",
        "Al ser de código abierto, Kafka tiene muchos plugins y extensiones. Una familia de extensiones se llaman *Conectores*. Estos sirven tanto para consumir data de alguna fuente o escribir data a alguna otra fuente. Los conectores de lectura se les llama *Source* o fuente, y los de escritura son *Sink* o \"pileta\"/\"hundir\"/\"caer\". Existen conectores como `MongoDBSink`, `BigQuerySink`, `Pub Sub Sink y Source`, etc.\n",
        "\n",
        "## Características principales de Kafka\n",
        "\n",
        "### Alto throughput\n",
        "\n",
        "Envía mensajes en una red limitada en throughput utilizando un cluster de máquinas con latencias tan bajas como 2ms.\n",
        "\n",
        "### Escalable\n",
        "\n",
        "Kafka permite escalar clusters hasta miles de *brokers*, trillones de mensajes por día, petabytes de data, en cientos de miles de *particiones*. Puede escalar elásticamente en storage y procesamiento.\n",
        "\n",
        "### Storage permanente\n",
        "\n",
        "Guarda los streams en un cluster distribuido, durable, y tolerante a fallas (noten las similitudes con Spark).\n",
        "\n",
        "### Alta disponibilidad\n",
        "\n",
        "Puede incrementar el tamaño de clusters eficientemente entre *availability zones* o conectar clusters entre diferentes regiones geográficas."
      ],
      "metadata": {
        "id": "VjjAK8QGtUye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.12-3.4.1/bin/zookeeper-server-start.sh -daemon ./kafka_2.12-3.4.1/config/zookeeper.properties\n",
        "!./kafka_2.12-3.4.1/bin/kafka-server-start.sh -daemon ./kafka_2.12-3.4.1/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 20\n",
        "!ps -ef | grep kafka\n",
        "# iniciando el tópico iris con replicación 1 y 1 partición\n",
        "!./kafka_2.12-3.4.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic iris\n",
        "!./kafka_2.12-3.4.1/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic iris"
      ],
      "metadata": {
        "id": "qvR5oqlxeOvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2550de2-c748-4547-f849-4d81872ea320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 10 secs until kafka and zookeeper services are up and running\n",
            "root        1017       1  0 19:40 ?        00:00:07 java -Xmx512M -Xms512M -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.12-3.4.1/bin/../logs/zookeeper-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.12-3.4.1/bin/../logs -Dlog4j.configuration=file:./kafka_2.12-3.4.1/bin/../config/log4j.properties -cp /content/kafka_2.12-3.4.1/bin/../libs/activation-1.1.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/audience-annotations-0.13.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-api-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-basic-auth-extension-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-json-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-mirror-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-mirror-client-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-runtime-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-transforms-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-annotations-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-core-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-databind-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-dataformat-csv-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-datatype-jdk8-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-jaxrs-base-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-jaxrs-json-provider-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-module-jaxb-annotations-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-module-scala_2.12-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/content/kafka_2.12-3.4.1/bin/../libs/javassist-3.29.2-GA.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.activation-api-1.2.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.annotation-api-1.3.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jaxb-api-2.3.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-client-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-common-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-hk2-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-server-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-client-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-continuation-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-http-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-io-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-security-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-server-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-servlet-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-servlets-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-util-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-util-ajax-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jline-3.22.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/jose4j-0.9.3.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka_2.12-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-clients-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-group-coordinator-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-log4j-appender-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-metadata-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-raft-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-server-common-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-shell-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-storage-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-storage-api-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-examples-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-scala_2.12-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-test-utils-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-tools-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/lz4-java-1.8.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/maven-artifact-3.8.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-buffer-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-codec-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-common-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-handler-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-resolver-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-classes-epoll-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-native-epoll-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-native-unix-common-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.12-3.4.1/bin/../libs/paranamer-2.8.jar:/content/kafka_2.12-3.4.1/bin/../libs/plexus-utils-3.3.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.12-3.4.1/bin/../libs/reload4j-1.2.25.jar:/content/kafka_2.12-3.4.1/bin/../libs/rocksdbjni-7.1.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-collection-compat_2.12-2.10.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-library-2.12.15.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-logging_2.12-3.9.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-reflect-2.12.15.jar:/content/kafka_2.12-3.4.1/bin/../libs/slf4j-api-1.7.36.jar:/content/kafka_2.12-3.4.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/content/kafka_2.12-3.4.1/bin/../libs/snappy-java-1.1.8.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/swagger-annotations-2.2.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/trogdor-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/zookeeper-3.6.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/zookeeper-jute-3.6.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/zstd-jni-1.5.2-1.jar org.apache.zookeeper.server.quorum.QuorumPeerMain ./kafka_2.12-3.4.1/config/zookeeper.properties\n",
            "root        1386       1  2 19:40 ?        00:02:27 java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.12-3.4.1/bin/../logs/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.12-3.4.1/bin/../logs -Dlog4j.configuration=file:./kafka_2.12-3.4.1/bin/../config/log4j.properties -cp /content/kafka_2.12-3.4.1/bin/../libs/activation-1.1.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/audience-annotations-0.13.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-api-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-basic-auth-extension-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-json-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-mirror-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-mirror-client-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-runtime-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/connect-transforms-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-annotations-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-core-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-databind-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-dataformat-csv-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-datatype-jdk8-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-jaxrs-base-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-jaxrs-json-provider-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-module-jaxb-annotations-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jackson-module-scala_2.12-2.13.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.12-3.4.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/content/kafka_2.12-3.4.1/bin/../libs/javassist-3.29.2-GA.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.activation-api-1.2.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.annotation-api-1.3.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jaxb-api-2.3.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-client-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-common-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-hk2-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jersey-server-2.39.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-client-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-continuation-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-http-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-io-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-security-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-server-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-servlet-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-servlets-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-util-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jetty-util-ajax-9.4.51.v20230217.jar:/content/kafka_2.12-3.4.1/bin/../libs/jline-3.22.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/jose4j-0.9.3.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka_2.12-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-clients-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-group-coordinator-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-log4j-appender-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-metadata-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-raft-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-server-common-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-shell-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-storage-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-storage-api-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-examples-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-scala_2.12-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-streams-test-utils-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/kafka-tools-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/lz4-java-1.8.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/maven-artifact-3.8.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-buffer-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-codec-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-common-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-handler-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-resolver-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-classes-epoll-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-native-epoll-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/netty-transport-native-unix-common-4.1.92.Final.jar:/content/kafka_2.12-3.4.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.12-3.4.1/bin/../libs/paranamer-2.8.jar:/content/kafka_2.12-3.4.1/bin/../libs/plexus-utils-3.3.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.12-3.4.1/bin/../libs/reload4j-1.2.25.jar:/content/kafka_2.12-3.4.1/bin/../libs/rocksdbjni-7.1.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-collection-compat_2.12-2.10.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-library-2.12.15.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-logging_2.12-3.9.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/scala-reflect-2.12.15.jar:/content/kafka_2.12-3.4.1/bin/../libs/slf4j-api-1.7.36.jar:/content/kafka_2.12-3.4.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/content/kafka_2.12-3.4.1/bin/../libs/snappy-java-1.1.8.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/swagger-annotations-2.2.0.jar:/content/kafka_2.12-3.4.1/bin/../libs/trogdor-3.4.1.jar:/content/kafka_2.12-3.4.1/bin/../libs/zookeeper-3.6.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/zookeeper-jute-3.6.4.jar:/content/kafka_2.12-3.4.1/bin/../libs/zstd-jni-1.5.2-1.jar kafka.Kafka ./kafka_2.12-3.4.1/config/server.properties\n",
            "root        2267     326  4 19:40 ?        00:04:57 /usr/lib/jvm/java-11-openjdk-amd64/bin/java -cp /usr/local/lib/python3.10/dist-packages/pyspark/conf:/usr/local/lib/python3.10/dist-packages/pyspark/jars/* -Xmx1g org.apache.spark.deploy.SparkSubmit --master local[*] --conf spark.master=local[*] --conf spark.app.name=Spark Streaming --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0,org.apache.kafka:kafka-clients:2.8.1 pyspark-shell\n",
            "root       29748     326  0 21:25 ?        00:00:00 /bin/bash -c ps -ef | grep kafka\n",
            "root       29750   29748  0 21:25 ?        00:00:00 grep kafka\n",
            "Error while executing topic command : Topic 'iris' already exists.\n",
            "[2023-10-02 21:25:59,909] ERROR org.apache.kafka.common.errors.TopicExistsException: Topic 'iris' already exists.\n",
            " (kafka.admin.TopicCommand$)\n",
            "Topic: iris\tTopicId: fKV41HHjSnC1u1Lv0Z00ZA\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: \n",
            "\tTopic: iris\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Ay41MvixBu"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hixfwphmiyUX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "from uuid import uuid4\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.types import StructType, DoubleType, StringType, IntegerType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col, udf, from_json, to_json, struct, md5\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import (\n",
        "    MinMaxScaler,\n",
        "    VectorAssembler,\n",
        "    OneHotEncoder,\n",
        "    StringIndexer,\n",
        "    IndexToString\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creando el cluster de Spark con las dependencias instaladas\n",
        "\n",
        "En este caso, en vez de usar archivos JAR, estamos especificando los paquetes que necesitamos y Spark se encarga de descargarlos por nosotros (si no estuvieran presentes).\n",
        "\n",
        "Adicionalmente, se crea el cluster de Spark con `local[*]` para que el cluster decida la cantidad de threads que necesita para correr el notebook."
      ],
      "metadata": {
        "id": "owopwYT02Hk9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1stM2jzAgjqq"
      },
      "outputs": [],
      "source": [
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0,org.apache.kafka:kafka-clients:2.8.1 --master local[*] pyspark-shell'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"Spark Streaming\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando el dataset\n",
        "\n",
        "En el siguiente bloque se define el schema. En la mayoría de los casos esto no es necesario, pero como las columnas del dataset `iris.csv` tienen puntos en los nombres: `sepal.width` Spark entiende que es un `Struct` o un objeto y trata de descomponerlo. Como no puede, este falla. Lo que hacemos para solucionar esto es cambiarle el nombre agregando *backticks* (el siguiente caracter: `)\n",
        "\n",
        "En este caso, vamos a usar la función `cache()` al final de la definición del dataset. Esto sirve para mantener el dataset en memoria y que las operaciones sean mucho más rapidas. Hacemos esto ya que luego vamos a ver como se pueden usar un dataset estático y streaming en conjunto."
      ],
      "metadata": {
        "id": "5gVrUFGP21wO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxMtCwi6jHwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a7605c-dd7e-4de1-ed06-d7b981a3ff60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+------------+-------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.7| Setosa|\n",
            "|        3.4|         4.6|        0.3|         1.4| Setosa|\n",
            "|        3.4|         5.0|        0.2|         1.5| Setosa|\n",
            "|        2.9|         4.4|        0.2|         1.4| Setosa|\n",
            "|        3.1|         4.9|        0.1|         1.5| Setosa|\n",
            "|        3.7|         5.4|        0.2|         1.5| Setosa|\n",
            "|        3.4|         4.8|        0.2|         1.6| Setosa|\n",
            "|        3.0|         4.8|        0.1|         1.4| Setosa|\n",
            "|        3.0|         4.3|        0.1|         1.1| Setosa|\n",
            "|        4.0|         5.8|        0.2|         1.2| Setosa|\n",
            "|        4.4|         5.7|        0.4|         1.5| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.3| Setosa|\n",
            "|        3.5|         5.1|        0.3|         1.4| Setosa|\n",
            "|        3.8|         5.7|        0.3|         1.7| Setosa|\n",
            "|        3.8|         5.1|        0.3|         1.5| Setosa|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- variety: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "iris_schema = StructType().add('sepal.length', DoubleType()) \\\n",
        "  .add('sepal.width', DoubleType()) \\\n",
        "  .add('petal.length', DoubleType()) \\\n",
        "  .add('petal.width', DoubleType()) \\\n",
        "  .add('variety', StringType())\n",
        "\n",
        "# renaming columns to remove dot for better compatibility\n",
        "iris_df = spark.read.format('csv') \\\n",
        "  .schema(iris_schema) \\\n",
        "  .option('header', 'true') \\\n",
        "  .load('iris.csv') \\\n",
        "  .select(\n",
        "      col('`sepal.width`').alias('sepal_width'),\n",
        "      col('`sepal.length`').alias('sepal_length'),\n",
        "      col('`petal.width`').alias('petal_width'),\n",
        "      col('`petal.length`').alias('petal_length'),\n",
        "      col('variety')\n",
        "    ).cache()\n",
        "iris_df.show()\n",
        "iris_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Openscoring y copia de modelos\n",
        "\n",
        "**NOTA IMPORTANTE**: en los comandos `cp` de las celdas que siguen, deben ponerse la dirección de su drive donde apunte a estos archivos. Los archivos estan disponibles en la carpeta del colab. Para conectar colab con drive, abrir los archivos (botón arriba a la izquierda que es una carpeta) y arriba de todo habrá un ícono de drive. Si se le da click se conecta y se agrega una carpeta llamada **drive** en la dirección `/content/drive`."
      ],
      "metadata": {
        "id": "MqnCnCHbEgKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1s-xeRtOjoy",
        "outputId": "86269e08-2d5e-4fae-b8e8-81f4ab186a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTmTL6xZPbDY",
        "outputId": "273171d4-f33c-4f9b-d92c-de69812772a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "!nohup java -jar /content/openscoring-server-executable-2.1.0.jar --port 8081 &\n",
        "!sleep 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTA IMPORTANTE**: el path debe ser donde cada uno guardo la carpeta_index_to_class y RandomForestIris.pmml\n",
        "El link donde encuentran la carpeta index_to_class y el archivo PMML es: https://drive.google.com/drive/folders/135dwjynARvhTEAtdS2dm85aiYqLXLKzR?usp=sharing"
      ],
      "metadata": {
        "id": "h9vN6gLtkLwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./drive/MyDrive/Other/Humai/Clase_5_Spark_Streaming/index_to_class ./index_to_string\n",
        "!cp -r ./drive/MyDrive/Other/Humai/Clase_5_Spark_Streaming/RandomForestIris.pmml ."
      ],
      "metadata": {
        "id": "HkWp4uLmZJcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6670b2-f98f-4309-be5a-1ee34f76d5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat './drive/MyDrive/Other/Humai/Clase_5_Spark_Streaming/index_to_class': No such file or directory\n",
            "cp: cannot stat './drive/MyDrive/Other/Humai/Clase_5_Spark_Streaming/RandomForestIris.pmml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Locallity o Localidad de la Data\n",
        "\n",
        "Las personas que diseñaron Spark notaron que es más costoeficiente \"mover los cómputos\" que \"mover la data\". Es decir, es más barato ejecutar los computos donde esta la data que mover la data a donde esta el computo. Por eso, no solamente Spark es procesamiento distribuido, sino que usa un patrón crucial para su funcionamiento óptimo. Este es, tener en cuenta la **Localidad de los datos**. Esto significa que los procesamientos que se envían al cluster de Spark, deben intentar poder ser performados por las máquinas en donde la data esta y evitar el *shuffling* (que los datos de una maquina termine en otra, que vimos que es costoso).\n",
        "\n",
        "Es importante tener esto en cuenta al momento de diseñar un sistema utilizando las tecnologías vistas en este colab. Se podría pensar en una arquitectura con los modelos desplegados en la misma máquina donde esta la data, de esta manera las consultas no saldrían de esta y sería extremadamente rápido, a pesar de que fuera HTTP.\n",
        "\n",
        "Los invito a considerar diferentes opciones y conversarlas en el discord."
      ],
      "metadata": {
        "id": "MaCUWqGV402n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X PUT --data-binary @RandomForestIris.pmml -H \"Content-type: text/xml\" http://localhost:8081/openscoring/model/RandomForestIris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wUzTVy18yvY",
        "outputId": "759b9024-257f-4308-dbb0-2c5c693434c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\" : \"RandomForestIris\",\n",
            "  \"miningFunction\" : \"classification\",\n",
            "  \"summary\" : \"Ensemble model\",\n",
            "  \"properties\" : {\n",
            "    \"created.timestamp\" : \"2023-10-02T21:26:15.942+00:00\",\n",
            "    \"accessed.timestamp\" : null,\n",
            "    \"file.size\" : 319988,\n",
            "    \"file.checksum\" : \"4171fc0ca8040702d587d0d539d872d0ce089cf156510c8c0a0edc8ec19d5f13\",\n",
            "    \"model.version\" : null\n",
            "  },\n",
            "  \"schema\" : {\n",
            "    \"inputFields\" : [ {\n",
            "      \"id\" : \"sepal_length\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"sepal_width\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"petal_length\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"petal_width\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    } ],\n",
            "    \"targetFields\" : [ {\n",
            "      \"id\" : \"label\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"categorical\",\n",
            "      \"values\" : [ \"0.0\", \"1.0\", \"2.0\" ]\n",
            "    } ],\n",
            "    \"outputFields\" : [ {\n",
            "      \"id\" : \"prediction\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"probability(0)\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"probability(1)\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"probability(2)\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    } ]\n",
            "  }\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se define la UDF para la inferencia en tiempo real"
      ],
      "metadata": {
        "id": "Pt9VyKdGFJpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model_prediction(sepal_width, sepal_length, petal_width, petal_length):\n",
        "  body = {\n",
        "    'id': f'record-{uuid4()}',\n",
        "    'arguments': {'sepal_width': sepal_width, 'sepal_length': sepal_length,\n",
        "             'petal_width': petal_width, 'petal_length': petal_length}\n",
        "          }\n",
        "\n",
        "  headers = {\"Content-type\": \"application/json\"}\n",
        "  response = requests.post(url='http://localhost:8081/openscoring/model/RandomForestIris', json=body, headers=headers)\n",
        "\n",
        "  return response.json()['results']['prediction']\n",
        "\n",
        "\n",
        "make_model_prediction_udf = udf(make_model_prediction)"
      ],
      "metadata": {
        "id": "d95tSDA2gJt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se carga el modelo de `IndexToString` para pasar de la predicción numérica a la clase real"
      ],
      "metadata": {
        "id": "EROGXxkjFMZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_class = IndexToString.load('./index_to_string')"
      ],
      "metadata": {
        "id": "s_gc_QYWb0_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir results\n",
        "!mkdir checkpoint"
      ],
      "metadata": {
        "id": "4NuWhqfVWbsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c322bd55-9764-4db0-9b71-5bacbb851917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘results’: File exists\n",
            "mkdir: cannot create directory ‘checkpoint’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leyendo de Kafka\n",
        "\n",
        "En este paso se ejecuta la lectura de Kafka, pero no automáticamente ni directamente, sino que se comienza un proceso que va a leer la data cuando llegue, va a desarmar el json, va a ejecutar la predicción, y va a hacer un join con la data original para ver si se predijo bien o no. Esto se ejecuta de manera asincrónica."
      ],
      "metadata": {
        "id": "NBe6ADn6FTcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_schema = StructType().add('sepal_length', DoubleType()) \\\n",
        "  .add('sepal_width', DoubleType()) \\\n",
        "  .add('petal_length', DoubleType()) \\\n",
        "  .add('petal_width', DoubleType())\n",
        "\n",
        "streaming_df = spark \\\n",
        "  .readStream \\\n",
        "  .format(\"kafka\") \\\n",
        "  .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
        "  .option(\"subscribe\", \"iris\") \\\n",
        "  .load() \\\n",
        "  .select(from_json(col('value').cast('string'), source_schema).alias('value')) \\\n",
        "  .select(col('value.sepal_length').alias('sepal_length'),\n",
        "          col('value.sepal_width').alias('sepal_width'),\n",
        "          col('value.petal_length').alias('petal_length'),\n",
        "          col('value.petal_width').alias('petal_width')) \\\n",
        "  .select('*', make_model_prediction_udf('sepal_width', 'sepal_length',\n",
        "                                    'petal_width', 'petal_length') \\\n",
        "          .cast(IntegerType()).alias('prediction')) \\\n",
        "  .join(iris_df, ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']) \\\n",
        "  .withColumnRenamed('variety', 'original_class')\n",
        "\n",
        "streaming_df = index_to_class.transform(streaming_df)\n",
        "\n",
        "streaming_df.writeStream.outputMode('append').format('json').option('path', 'results').option('header', 'true').option(\"checkpointLocation\", \"checkpoint\").start()"
      ],
      "metadata": {
        "id": "-1sf4mn-VzZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6272860b-98a6-4c0e-e411-38e25dc995eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.StreamingQuery at 0x7edf23543f40>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Escribiendo a Kafka\n",
        "\n",
        "Ya iniciado el paso anterior, se escribe a Kafka el dataset completo. Esto llegara al proceso anterior y se hara la predicción. Para ver los resutlados, ir a la carpeta ubicada en `/content/results` y buscar los archivos que comienzan en `part-000...`. Ahi estan los resultados en formato json.\n",
        "\n",
        "En este caso como clave se eligió el hash de los valores de entrada. La realidad es que no hace diferencia ya que solo hay una partición."
      ],
      "metadata": {
        "id": "q1Jp_VC1FwWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !sleep 10\n",
        "\n",
        "iris_df \\\n",
        "  .sample(fraction=0.1) \\\n",
        "  .select(to_json(struct('sepal_width', 'sepal_length', 'petal_width', 'petal_length')).alias('value')) \\\n",
        "  .withColumn('key', md5('value')) \\\n",
        "  .selectExpr(\"key\", \"CAST(value AS STRING)\") \\\n",
        "  .write \\\n",
        "  .format(\"kafka\") \\\n",
        "  .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
        "  .option(\"topic\", \"iris\") \\\n",
        "  .save()"
      ],
      "metadata": {
        "id": "2Bi5cA5TiIuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"hola\" \\\n",
        "\" mundo\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PcwOxxpJV8iq",
        "outputId": "cabcf50f-b18f-4e89-ac12-a748d1c4fcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hola mundo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}